"""
Lyric scraping functions for the ACE‑Step Data‑Tool.

This module encapsulates the logic used to fetch song lyrics from
Genius.com based on a song’s title and artist metadata.  It also
provides helper functions for reading audio metadata, writing lyrics
files, and orchestrating the fetch and save process.  Logging is
performed via :func:`log_message` from :mod:`lyrics_tool.shared_logs`.

The functions defined here are designed to be called both from a
command‑line context and programmatically from a Gradio UI.  They
respect a configurable delay between requests to avoid hammering
Genius.com and support a simple fallback search if direct URL
construction fails.
"""

from __future__ import annotations

import os
import re
import time
from urllib.parse import quote

import requests
from bs4 import BeautifulSoup  # type: ignore
from tinytag import TinyTag  # type: ignore
# tqdm is intentionally not imported to avoid an unnecessary dependency

from .shared_logs import LOGS, log_message
from .metadata import clean_rap_metadata, normalize_string

# Configuration: HTTP headers and delay between requests
HEADERS: dict[str, str] = {
    'User-Agent': (
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'
    )
}
# Delay in seconds between successive requests to Genius.com.  Adjust if you
# encounter rate limiting.
REQUEST_DELAY: float = 1.5


def get_audio_metadata(file_path: str) -> dict[str, str]:
    """Read basic metadata (title, artist, album) from an audio file.

    Uses the TinyTag library to extract ID3 or equivalent tags.  If a
    particular tag is missing, a placeholder string (e.g. "Unknown
    Title") is returned instead.  Any metadata errors are logged and
    result in empty strings.

    Parameters
    ----------
    file_path: str
        Path to the audio file (mp3, wav, flac, etc.).

    Returns
    -------
    dict[str, str]
        A dictionary with keys ``title``, ``artist`` and ``album``.
    """
    try:
        tag = TinyTag.get(file_path)
        title = tag.title or 'Unknown Title'
        artist = tag.artist or 'Unknown Artist'
        album = tag.album or 'Unknown Album'
        log_message(f"🎵 [Tinytag] Title={title}, Artist={artist}")
        return {'title': title, 'artist': artist, 'album': album}
    except Exception as e:
        log_message(f"⚠️ Metadata errors: {e}")
        return {'title': '', 'artist': '', 'album': ''}


def process_single_file(file_path: str) -> bool:
    """Fetch and save lyrics for a single audio file.

    This is a convenience wrapper around :func:`get_lyrics` and
    writing the resulting lyrics to disk.  It constructs the output
    file name by appending ``_lyrics.txt`` to the base name of the
    audio file.  A header containing the artist and title is
    prepended to the file.  Returns ``True`` on success or ``False``
    if an error occurs.
    """
    try:
        meta = get_audio_metadata(file_path)
        artist = meta['artist']
        title = meta['title']
        lyrics = get_lyrics(artist, title)
        base = os.path.splitext(os.path.basename(file_path))[0]
        out_path = os.path.join(os.path.dirname(file_path), f"{base}_lyrics.txt")
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(f"Artist: {artist}\nTitle: {title}\n\n")
            f.write(lyrics)
        return True
    except Exception:
        return False


def scrape_genius_lyrics(artist: str, title: str) -> str:
    """Attempt to fetch lyrics by constructing direct Genius.com URLs.

    Two candidate URLs are generated by combining the normalised
    artist and title in both orders.  Each URL is requested in turn
    and, if a page is found, the HTML is parsed to extract the
    lyric containers.  Any extraneous annotation elements are
    removed.  If a non‑empty lyrics string is obtained it is
    returned immediately.  If no lyrics are found this function
    returns an empty string.
    """
    clean_artist = clean_rap_metadata(artist)
    clean_title = clean_rap_metadata(title)
    # Two URL variants
    url1 = f"https://genius.com/{normalize_string(clean_artist)}-{normalize_string(clean_title)}-lyrics"
    url2 = f"https://genius.com/{normalize_string(clean_title)}-{normalize_string(clean_artist)}-lyrics"

    # Debug output to help diagnose problems; printed to server logs
    print(f"💡 Generated URL1: {url1}")
    print(f"💡 Generated URL2: {url2}")

    for url in (url1, url2):
        log_message(f"⏳ Trying URL: {url}")
        resp = requests.get(url, headers=HEADERS)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            containers = soup.select("div[class*='Lyrics__Container']") or soup.find_all("div", {"data-lyrics-container": "true"})
            if containers:
                text = ''
                for c in containers:
                    for block in c.select(".ReferentFragmentdesktop__ClickTarget, .Label"):
                        block.decompose()
                    text += c.get_text(separator="\n", strip=True) + "\n\n"
                return text.replace("[", "\n[").replace("]", "]\n").strip()
    return ''


def genius_search_fallback(artist: str, title: str) -> str:
    """Fallback: search Genius.com for a song if direct URLs fail.

    Constructs a query from artist and title, performs a search, then
    scans the result page for links ending in ``/lyrics`` that also
    contain the artist’s name.  On finding a match, it scrapes
    lyrics from that URL using :func:`scrape_genius_lyrics_from_url`.
    Returns an empty string if no suitable link is found.
    """
    query = quote(f"{artist} {title}")
    search_url = f"https://genius.com/search?q={query}"
    print(f"Searching Genius: {search_url}")
    resp = requests.get(search_url, headers=HEADERS)
    soup = BeautifulSoup(resp.text, 'html.parser')
    links = soup.select("a[href*='/lyrics']")
    for link in links:
        href = link['href']
        if artist.lower() in link.get_text(strip=True).lower():
            return scrape_genius_lyrics_from_url(href)
    return ''


def scrape_genius_lyrics_from_url(url: str) -> str:
    """Scrape lyrics directly from a known Genius.com URL.

    Fetches the given page and collects text from all lyric containers.
    Returns an empty string if no containers are found.
    """
    resp = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(resp.text, 'html.parser')
    containers = soup.select("div[class*='Lyrics__Container']") or soup.find_all("div", {"data-lyrics-container": "true"})
    if containers:
        return "\n\n".join(c.get_text(separator="\n", strip=True) for c in containers)
    return ''


def get_lyrics(artist: str, title: str) -> str:
    """Orchestrate lyric retrieval using direct URLs and fallback search.

    Logs the search and, if necessary, inserts a delay before invoking
    the fallback to be polite to the remote server.  Returns the
    lyrics text on success or the marker string ``⚠️ Lyrics not found``
    on failure.
    """
    log_message(f"🔄 Search lyrics for: {artist} - {title}")
    lyrics = scrape_genius_lyrics(artist, title)
    if not lyrics:
        time.sleep(REQUEST_DELAY)
        lyrics = genius_search_fallback(artist, title)
    return lyrics or '⚠️ Lyrics not found'


def load_lyrics(file_path: str) -> str:
    """Load an existing lyrics file if it exists.

    Given a base file path (without the ``_lyrics.txt`` suffix), this
    helper will attempt to read and return the contents of the
    corresponding lyrics file.  If no such file is present an empty
    string is returned.
    """
    base = os.path.splitext(file_path)[0]
    path = f"{base}_lyrics.txt"
    return open(path, 'r', encoding='utf-8').read() if os.path.exists(path) else ''


def fetch_and_save_lyrics(artist: str, title: str, output_path: str) -> bool:
    """Fetch lyrics and write them directly to a specified output file.

    Returns ``True`` if lyrics were found and written, ``False``
    otherwise.  Unlike :func:`process_single_file`, this helper does
    not prepend artist and title headers to the output; it writes
    only the lyrics text.  It still ensures that the output
    directory exists.
    """
    lyrics = get_lyrics(artist, title)
    if not lyrics or lyrics.lower() == 'lyrics not found':
        return False
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(lyrics)
    return True


# Emit a log message when this module is imported so that the user
# knows the scraper is ready.  This is consistent with the original
# project behaviour.
log_message("... Lyric Scraper loaded ✅")
